% Generated by tools/generate-man.R -- do not edit by hand
\name{sse}
\alias{sse}
\title{Sum of Squared Errors}
\description{
Calculates sum of squared errors.
}
\usage{
sse(actual, predicted)
}
\arguments{
  \item{actual}{Actual values.}
  \item{predicted}{Predicted values. }
}
\value{
SSE value. 
}
\seealso{

Other statistics: \code{\link{autocorrel}}, \code{\link{autopcorrel}}, \code{\link{cmpsum}}, \code{\link{colN}}, \code{\link{colSds}}, \code{\link{covp}}, \code{\link{dependent.rank}}, \code{\link{print.cor}}, \code{\link{rank}}, \code{\link{rowSds}}, \code{\link{sdp}}, \code{\link{sst}}, \code{\link{summary}}, \code{\link{tabularsummary}}, \code{\link{varp}}
}
\examples{
\dontrun{
actual    <- c(1, 2, 3, 4, 5)
predicted <- c(1.1, 1.9, 3.2, 3.8, 5.1)

# Compute sum of squared errors
iaw$sse(actual, predicted)   # small positive number

# Perfect predictions give SSE of 0
iaw$sse(actual, actual)      # 0

# NA values are dropped automatically
iaw$sse(c(1, NA, 3), c(1, 2, 4))   # (3-4)^2 = 1

# Regression residual SSE matches sum of squared residuals
set.seed(42)
y <- 1:20 + rnorm(20)
fit <- lm(y ~ seq_along(y))
iaw$sse(y, fitted(fit))   # same as sum(resid(fit)^2)

# Compare two competing forecasts
actual <- c(100, 102, 105, 103, 108)
model_a <- c(101, 101, 106, 104, 107)
model_b <- c(99, 103, 104, 102, 110)
iaw$sse(actual, model_a)   # 4
iaw$sse(actual, model_b)   # 10 -- model A is better

# Single observation
iaw$sse(5, 3)   # 4

}
}
